{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SkLearn to get a sample regression dataset\n",
    "X, y1 = make_regression(n_samples=200, n_features=8, n_informative=5, n_targets=5, noise=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_size = y_train.shape[1]\n",
    "samples = X_train.shape[0]\n",
    "\n",
    "X_train = X_train.reshape(input_size, samples) # input_size x batch_size = 8 * 160 \n",
    "X_test = X_test.reshape(input_size, -1) # input_size x batch_size = 8 * 40 \n",
    "y_train = y_train.reshape(output_size,samples) # output_size x batch_size = 1 x 160\n",
    "y_test = y_test.reshape(output_size,-1) # output_size x batch_size = 1 x 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 160), (8, 40), (5, 160), (5, 40))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinearRegression():\n",
    "    def __init__(self, input_size, output_size, batch_size, lr):\n",
    "        self.weights = np.random.randn(output_size, input_size) # W: 1x8\n",
    "        self.bias = np.random.randn(output_size, batch_size) # 1x160\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        return\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        X = 8 x 160 (input_size x batch_size)\n",
    "        weights = 1 x 8 (output_size x input_size)\n",
    "        bias = 1 x 160 (output_size x batch_size)\n",
    "        '''\n",
    "        return np.dot(self.weights, X) + self.bias # output_size x 1 = 1x1\n",
    "\n",
    "    def backward(self, X, Y, Y_hat):\n",
    "        '''\n",
    "        All inputs are matrices.\n",
    "        X = 8 x 1 (input_size x 1)\n",
    "        Y = Y_hat = 1 x 160 (output_size x batch)\n",
    "\n",
    "        calculate the following gradients.\n",
    "        params update: dL/DW, dL/dB\n",
    "        dL/dY needed for chain rule calc of params\n",
    "\n",
    "        dL/dY = (2/n) * (Y - Y_hat)\n",
    "        dL/dW = dL/dY . X.T\n",
    "        dL/dB = dL/dY\n",
    "        '''\n",
    "        dL_dY = (2/self.batch_size) * np.subtract(Y, Y_hat) # (1 x 160)\n",
    "        dL_dW = np.dot(dL_dY, X.T) # (1 x 8)\n",
    "        dL_dB = dL_dY # (1 x 160)\n",
    "\n",
    "        self.weights-= self.lr*dL_dW\n",
    "        self.bias-= self.lr*dL_dB\n",
    "        return\n",
    "\n",
    "def mse_loss(Y, Y_hat):\n",
    "    '''\n",
    "    Y and Y_hat are vectors. mse = 1/n (summation((y-y_hat)**2))\n",
    "    Y = Y_hat = output_size x batch = 1 x 160\n",
    "    '''\n",
    "    e = np.subtract(Y, Y_hat)\n",
    "    n = Y.shape[1]\n",
    "    return (1/n) * np.sum(np.square(e)) # to return element-wise square of the array input, use the numpy.square() method\n",
    "    # return np.sum((e)**2) # works the same as above\n",
    "    # return np.matmul(e.T, e)  # CF = e_T * e perform summation over all squared errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for training\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "model = MultiLinearRegression(input_size=input_size, output_size=output_size, batch_size=samples, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 106925.9871 at epoch 0/100\n",
      "Loss = 107398.8235 at epoch 20/100\n",
      "Loss = 107909.2811 at epoch 40/100\n",
      "Loss = 108460.8641 at epoch 60/100\n",
      "Loss = 109057.4167 at epoch 80/100\n",
      "Average Train MSE loss over 100 epochs = 108210.703\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    # forward pass - get prediction\n",
    "    Y_hat = model.forward(X_train) # X_train: (8 x 160), Y_hat :(1 x 160)\n",
    "    \n",
    "    # loss\n",
    "    loss = mse_loss(y_train, Y_hat) # loss : scalar\n",
    "    train_loss.append(loss)\n",
    "\n",
    "    # backward pass - update gradients\n",
    "    '''\n",
    "    model.weights.shape : (1, 8), model.bias.shape : (1, 160)\n",
    "    '''\n",
    "    model.backward(X_train, y_train, Y_hat)\n",
    "    if epoch%20==0:\n",
    "        print(f'Loss = {round(loss,4)} at epoch {epoch}/{epochs}')\n",
    "\n",
    "print(f\"Average Train MSE loss over {epochs} epochs = {round(np.average(train_loss),4)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
