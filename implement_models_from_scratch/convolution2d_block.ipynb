{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.randint(low=0, high=255, size=(28,28,3))\n",
    "filters = np.random.rand(4,3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 3), (4, 3, 3, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape, filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the image\n",
    "image = (image - np.mean(image))/np.std(image)\n",
    "\n",
    "# reshape image\n",
    "image = image.reshape(3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_2d(input_a, input_b):\n",
    "    output = 0.0\n",
    "    size_h, size_w = input_a.shape\n",
    "    for h in range(size_h):\n",
    "        for w in range(size_w):\n",
    "            output+= input_a[h,w]*input_b[h,w]\n",
    "    return output\n",
    "\n",
    "def conv2d(image, filters, padding=0, stride=1):\n",
    "    in_features, image_h, image_w = image.shape\n",
    "    out_features, in_features, kernel_h, kernel_w = filters.shape\n",
    "\n",
    "    out_h, out_w = ((image_h - kernel_h + 2*padding)//stride) + 1, \\\n",
    "                    ((image_w - kernel_w + 2*padding)//stride) + 1\n",
    "    out_shape = (out_features, out_h, out_w)\n",
    "\n",
    "    out_feature_maps = np.zeros(out_shape)\n",
    "\n",
    "    for b in range(out_features):\n",
    "        # working on feature map i\n",
    "        for c in range(in_features):\n",
    "            # working with kernels present in filter bank b starting with channel c\n",
    "            kernels_channel = filters[b,c] # (3x3)\n",
    "            image_channel = image[c] # (28x28)\n",
    "            for h in range(out_h):\n",
    "                for w in range(out_w):\n",
    "                    sub_image = image_channel[h:h+kernel_h,w:w+kernel_w] # (3x3)\n",
    "                    out_feature_maps[b,h,w] += correlate_2d(sub_image, kernels_channel) # add feature map from each channel\n",
    "    \n",
    "    return out_feature_maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "out_feature_map = conv2d(image=image, filters=filters)\n",
    "print(out_feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.Size([4, 26, 26])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "img_torch = torch.from_numpy(image).unsqueeze(0) #torch.Size([1, 3, 28, 28])\n",
    "filter_torch = torch.from_numpy(filters).double() #torch.Size([1, 4, 3, 3])\n",
    "print(filter_torch.dtype)\n",
    "torch_out_map = F.conv2d(input=img_torch, weight=filter_torch ).squeeze(0) #torch.Size([4, 26, 26])\n",
    "\n",
    "print(torch_out_map.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing my conv2d block result against torch.nn.function conv2d layer result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3750, -0.5946,  4.0895,  6.7314,  2.0902, -0.8388, -3.5884, -3.4262,\n",
       "         3.4433, -0.2526,  3.1783,  3.5102,  2.4618,  0.2534, -0.8105, -3.4138,\n",
       "        -1.7774, -2.9848, -2.5354, -2.0769,  2.5116,  0.6277, -1.1215, -6.1133,\n",
       "        -2.2196, -1.1763], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out_map[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37496551, -0.59459855,  4.08952516,  6.73139188,  2.09022551,\n",
       "       -0.83877008, -3.58835423, -3.42622705,  3.44327755, -0.25255388,\n",
       "        3.17825356,  3.51015505,  2.46181831,  0.25344319, -0.81046311,\n",
       "       -3.41375309, -1.77743724, -2.98484678, -2.53541136, -2.07690163,\n",
       "        2.5116195 ,  0.62768895, -1.12153036, -6.11330317, -2.21961838,\n",
       "       -1.17625347])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_feature_map[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out_feature_map_numpy = torch_out_map.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.129904361417684e-18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(torch_out_feature_map_numpy-out_feature_map) # error between the two feature maps is close to zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
